"""
COMPLETE CAROUSELL CLOTHING CLASSIFIER
======================================
Features:
1. Check for existing trained model first
2. Skip training if model exists
3. Interactive prediction mode
4. Send image path and get classification
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
import numpy as np
import matplotlib.pyplot as plt
import os
import json
from datetime import datetime

print("\n" + "="*80)
print("üß• CAROUSELL CLOTHING CLASSIFIER - COMPLETE SYSTEM")
print("="*80)

# ============================================================================
# CONFIGURATION
# ============================================================================

IMG_SIZE = 224
BATCH_SIZE = 32
INITIAL_EPOCHS = 15
FINE_TUNE_EPOCHS = 25
INITIAL_LR = 0.001
FINE_TUNE_LR = 0.0001

TRAIN_DIR = 'Clothes_Dataset_Train'
VAL_DIR = 'Clothes_Dataset_Val'
MODEL_PATH = 'models/carousell_clothing_model.keras'
BEST_MODEL_PATH = 'models/carousell_clothing_model_best.keras'
CLASS_NAMES_PATH = 'models/class_names.json'
HISTORY_PATH = 'outputs/training_history.json'
PLOT_PATH = 'outputs/training_history.png'

os.makedirs('models', exist_ok=True)
os.makedirs('outputs', exist_ok=True)

CLASS_NAMES_MAPPING = {
    'Blazer': 'Blazer üß•',
    'Celana_Panjang': 'Long Pants üëñ',
    'Celana_Pendek': 'Shorts ü©≥',
    'Gaun': 'Dress üëó',
    'Hoodie': 'Hoodie üß•',
    'Jaket': 'Jacket üß•',
    'Jaket_Denim': 'Denim Jacket üß•',
    'Jaket_Olahraga': 'Sports Jacket üèÉ',
    'Jeans': 'Jeans üëñ',
    'Kaos': 'T-Shirt üëï',
    'Kemeja': 'Shirt üëî',
    'Mantel': 'Coat üß•',
    'Polo': 'Polo Shirt üëï',
    'Rok': 'Skirt üëó',
    'Sweter': 'Sweater üß∂'
}

# ============================================================================
# PREDICTION FUNCTIONS
# ============================================================================

def load_trained_model():
    """Load existing trained model"""
    # Try best model first, then regular model
    model_to_load = BEST_MODEL_PATH if os.path.exists(BEST_MODEL_PATH) else MODEL_PATH
    
    if not os.path.exists(model_to_load):
        return None, None
    
    if not os.path.exists(CLASS_NAMES_PATH):
        return None, None
    
    try:
        print(f"\nüîÑ Loading model from: {model_to_load}")
        model = keras.models.load_model(model_to_load)
        
        with open(CLASS_NAMES_PATH, 'r') as f:
            class_names = json.load(f)
        
        print(f"‚úÖ Model loaded successfully!")
        print(f"   Classes: {len(class_names)}")
        print(f"   Model: {os.path.basename(model_to_load)}")
        
        return model, class_names
        
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return None, None

def predict_image(model, class_names, image_path, show_plot=True):
    """Predict clothing type from image"""
    
    if not os.path.exists(image_path):
        print(f"\n‚ùå ERROR: Image not found: {image_path}")
        return None
    
    try:
        # Load and preprocess image
        print(f"\nüîç Analyzing image: {os.path.basename(image_path)}")
        
        img = keras.preprocessing.image.load_img(
            image_path,
            target_size=(IMG_SIZE, IMG_SIZE)
        )
        img_array = keras.preprocessing.image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0)
        
        # Make prediction
        predictions = model.predict(img_array, verbose=0)[0]
        predicted_idx = np.argmax(predictions)
        predicted_class = class_names[predicted_idx]
        confidence = predictions[predicted_idx]
        
        # Get top 5 predictions
        top_5_indices = np.argsort(predictions)[-5:][::-1]
        
        # Display results
        print("\n" + "="*80)
        print(f"üì∏ PREDICTION RESULTS")
        print("="*80)
        
        display_name = CLASS_NAMES_MAPPING.get(predicted_class, predicted_class)
        print(f"\nüéØ THIS IS: {display_name}")
        print(f"üìä Confidence: {confidence:.2%}")
        
        print(f"\nüìã Top 5 Predictions:")
        print("-" * 80)
        for i, idx in enumerate(top_5_indices, 1):
            cls = class_names[idx]
            display = CLASS_NAMES_MAPPING.get(cls, cls)
            conf = predictions[idx]
            bar = "‚ñà" * int(conf * 40)
            print(f"  {i}. {display:<30} {conf:>6.2%}  {bar}")
        print("="*80 + "\n")
        
        # Show image with prediction
        if show_plot:
            plt.figure(figsize=(10, 8))
            plt.imshow(img)
            plt.axis('off')
            
            title_text = f"{display_name}\nConfidence: {confidence:.2%}"
            plt.title(title_text, fontsize=16, fontweight='bold', pad=20)
            
            plt.tight_layout()
            
            # Save prediction result
            output_path = os.path.join('outputs', f'prediction_{os.path.basename(image_path)}')
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            print(f"üíæ Prediction image saved: {output_path}")
            
            try:
                plt.show()
            except:
                pass
            
            plt.close()
        
        return {
            'image': os.path.basename(image_path),
            'prediction': predicted_class,
            'display_name': display_name,
            'confidence': float(confidence),
            'top_5': [(class_names[idx], float(predictions[idx])) for idx in top_5_indices]
        }
        
    except Exception as e:
        print(f"\n‚ùå Error during prediction: {e}")
        import traceback
        traceback.print_exc()
        return None

def interactive_prediction_mode(model, class_names):
    """Interactive mode for predictions"""
    print("\n" + "="*80)
    print("üé≠ INTERACTIVE PREDICTION MODE")
    print("="*80)
    print("\nAvailable classes:")
    for i, cls in enumerate(class_names, 1):
        display = CLASS_NAMES_MAPPING.get(cls, cls)
        print(f"  {i:2d}. {display}")
    
    print("\n" + "="*80)
    print("üìù INSTRUCTIONS:")
    print("  ‚Ä¢ Enter the path to an image file")
    print("  ‚Ä¢ Type 'quit' or 'exit' to stop")
    print("  ‚Ä¢ Type 'batch' to predict multiple images")
    print("="*80 + "\n")
    
    while True:
        user_input = input("üìÅ Enter image path (or command): ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("\nüëã Exiting prediction mode. Goodbye!")
            break
        
        elif user_input.lower() == 'batch':
            print("\nüì¶ Batch prediction mode")
            print("Enter image paths (one per line). Type 'done' when finished.\n")
            
            image_paths = []
            while True:
                path = input(f"  Image {len(image_paths)+1}: ").strip()
                if path.lower() == 'done':
                    break
                if path:
                    image_paths.append(path)
            
            if image_paths:
                print(f"\nüîÑ Processing {len(image_paths)} images...\n")
                results = []
                for i, img_path in enumerate(image_paths, 1):
                    print(f"\n[{i}/{len(image_paths)}]")
                    result = predict_image(model, class_names, img_path, show_plot=False)
                    if result:
                        results.append(result)
                
                # Summary
                if results:
                    print("\n" + "="*80)
                    print("üìä BATCH PREDICTION SUMMARY")
                    print("="*80)
                    for idx, res in enumerate(results, 1):
                        print(f"{idx}. {res['image']:<40} ‚Üí {res['display_name']} ({res['confidence']:.2%})")
                    print("="*80 + "\n")
        
        elif user_input:
            predict_image(model, class_names, user_input, show_plot=True)
        
        else:
            print("‚ö†Ô∏è  Please enter a valid image path or command")

# ============================================================================
# TRAINING FUNCTIONS
# ============================================================================

def check_dataset_exists():
    """Check if training dataset exists"""
    if not os.path.exists(TRAIN_DIR):
        print(f"\n‚ùå ERROR: Training directory not found: {TRAIN_DIR}")
        return False
    
    if not os.path.exists(VAL_DIR):
        print(f"\n‚ùå ERROR: Validation directory not found: {VAL_DIR}")
        return False
    
    return True

def train_model():
    """Complete training process"""
    
    print("\n" + "="*80)
    print("üèãÔ∏è STARTING TRAINING PROCESS")
    print("="*80)
    
    # Check directories
    if not check_dataset_exists():
        print("\nPlease ensure your dataset is organized as:")
        print(f"  {TRAIN_DIR}/")
        print(f"    ‚îú‚îÄ‚îÄ Blazer/")
        print(f"    ‚îú‚îÄ‚îÄ Celana_Panjang/")
        print(f"    ‚îî‚îÄ‚îÄ ... (other classes)")
        print(f"\n  {VAL_DIR}/")
        print(f"    ‚îú‚îÄ‚îÄ Blazer/")
        print(f"    ‚îú‚îÄ‚îÄ Celana_Panjang/")
        print(f"    ‚îî‚îÄ‚îÄ ... (other classes)")
        return None, None
    
    # Create data generators
    print("\n[CREATE] Data Generators...")
    
    train_datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )
    
    val_datagen = ImageDataGenerator()
    
    train_generator = train_datagen.flow_from_directory(
        TRAIN_DIR,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=True
    )
    
    validation_generator = val_datagen.flow_from_directory(
        VAL_DIR,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        shuffle=False
    )
    
    print(f"‚úì Training samples:   {train_generator.samples:,}")
    print(f"‚úì Validation samples: {validation_generator.samples:,}")
    
    class_names = sorted(list(train_generator.class_indices.keys()))
    num_classes = len(class_names)
    
    print(f"‚úì Classes: {num_classes}")
    
    # Build model
    print("\n[BUILD] Model...")
    
    base_model = MobileNetV2(
        input_shape=(IMG_SIZE, IMG_SIZE, 3),
        include_top=False,
        weights='imagenet'
    )
    base_model.trainable = False
    
    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    x = layers.Rescaling(1./255)(inputs)
    x = base_model(x, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(512, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.4)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = models.Model(inputs, outputs)
    
    print("‚úì Model built")
    
    # Phase 1: Train with frozen base
    print("\n" + "="*80)
    print("üöÄ PHASE 1: Initial Training (Frozen Base)")
    print("="*80)
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=INITIAL_LR),
        loss='categorical_crossentropy',
        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]
    )
    
    callbacks_phase1 = [
        callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-7,
            verbose=1
        ),
        callbacks.ModelCheckpoint(
            BEST_MODEL_PATH,
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    history_phase1 = model.fit(
        train_generator,
        epochs=INITIAL_EPOCHS,
        validation_data=validation_generator,
        callbacks=callbacks_phase1,
        verbose=1
    )
    
    # Phase 2: Fine-tuning
    print("\n" + "="*80)
    print("üöÄ PHASE 2: Fine-Tuning")
    print("="*80)
    
    base_model.trainable = True
    for layer in base_model.layers[:-30]:
        layer.trainable = False
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),
        loss='categorical_crossentropy',
        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]
    )
    
    callbacks_phase2 = [
        callbacks.EarlyStopping(
            monitor='val_loss',
            patience=7,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=4,
            min_lr=1e-8,
            verbose=1
        ),
        callbacks.ModelCheckpoint(
            BEST_MODEL_PATH,
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
    ]
    
    history_phase2 = model.fit(
        train_generator,
        epochs=FINE_TUNE_EPOCHS,
        validation_data=validation_generator,
        callbacks=callbacks_phase2,
        verbose=1
    )
    
    # Combine histories
    combined_history = {
        'loss': history_phase1.history['loss'] + history_phase2.history['loss'],
        'accuracy': history_phase1.history['accuracy'] + history_phase2.history['accuracy'],
        'val_loss': history_phase1.history['val_loss'] + history_phase2.history['val_loss'],
        'val_accuracy': history_phase1.history['val_accuracy'] + history_phase2.history['val_accuracy'],
    }
    
    # Save results
    print("\n[SAVE] Saving results...")
    
    model.save(MODEL_PATH)
    print(f"‚úì Model saved: {MODEL_PATH}")
    
    with open(CLASS_NAMES_PATH, 'w') as f:
        json.dump(class_names, f, indent=2)
    print(f"‚úì Class names saved: {CLASS_NAMES_PATH}")
    
    history_serializable = {k: [float(v) for v in vals] for k, vals in combined_history.items()}
    with open(HISTORY_PATH, 'w') as f:
        json.dump(history_serializable, f, indent=2)
    print(f"‚úì History saved: {HISTORY_PATH}")
    
    # Plot
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    epochs_range = range(1, len(combined_history['accuracy']) + 1)
    
    axes[0].plot(epochs_range, combined_history['accuracy'], 'b-', label='Training')
    axes[0].plot(epochs_range, combined_history['val_accuracy'], 'r-', label='Validation')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Accuracy')
    axes[0].set_title('Model Accuracy')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    axes[1].plot(epochs_range, combined_history['loss'], 'b-', label='Training')
    axes[1].plot(epochs_range, combined_history['val_loss'], 'r-', label='Validation')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Loss')
    axes[1].set_title('Model Loss')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(PLOT_PATH, dpi=300)
    print(f"‚úì Plot saved: {PLOT_PATH}")
    
    try:
        plt.show()
    except:
        pass
    
    plt.close()
    
    # Final results
    final_val_acc = combined_history['val_accuracy'][-1]
    print(f"\n" + "="*80)
    print(f"‚úÖ TRAINING COMPLETE!")
    print(f"="*80)
    print(f"Final Validation Accuracy: {final_val_acc:.2%}")
    print(f"Model saved to: {MODEL_PATH}")
    print(f"Best model saved to: {BEST_MODEL_PATH}")
    
    return model, class_names

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution function"""
    
    print("\nüîç Checking for existing trained model...")
    
    # Try to load existing model
    model, class_names = load_trained_model()
    
    if model is not None and class_names is not None:
        # Model exists - go straight to prediction
        print("\n‚úÖ Found trained model! Skipping training.")
        print("\n" + "="*80)
        print("MENU OPTIONS:")
        print("="*80)
        print("  1. Start prediction mode (classify images)")
        print("  2. Retrain model from scratch")
        print("  3. Exit")
        print("="*80)
        
        choice = input("\nEnter your choice (1-3): ").strip()
        
        if choice == '1':
            interactive_prediction_mode(model, class_names)
        elif choice == '2':
            print("\n‚ö†Ô∏è  This will retrain the model from scratch.")
            confirm = input("Are you sure? (yes/no): ").strip().lower()
            if confirm == 'yes':
                model, class_names = train_model()
                if model is not None:
                    print("\n‚úÖ Training completed! Starting prediction mode...")
                    interactive_prediction_mode(model, class_names)
        else:
            print("\nüëã Exiting. Goodbye!")
    
    else:
        # No model found - need to train
        print("\n‚ö†Ô∏è  No trained model found. Training required.")
        print("\n" + "="*80)
        print("OPTIONS:")
        print("="*80)
        print("  1. Train model now")
        print("  2. Exit")
        print("="*80)
        
        choice = input("\nEnter your choice (1-2): ").strip()
        
        if choice == '1':
            model, class_names = train_model()
            if model is not None:
                print("\n‚úÖ Training completed! Starting prediction mode...")
                interactive_prediction_mode(model, class_names)
        else:
            print("\nüëã Exiting. Goodbye!")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interrupted by user")
        print("üëã Exiting gracefully...")
    except Exception as e:
        print(f"\n\n‚ùå An error occurred: {e}")
        import traceback
        traceback.print_exc()